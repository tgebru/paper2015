\documentclass[10pt,twocolumn,letterpaper]{article}

\usepackage{cvpr}
\usepackage{times}
\usepackage{epsfig}
\usepackage{graphicx}
\usepackage{amsmath}
\usepackage{amssymb}

% Include other packages here, before hyperref.

% If you comment hyperref and then uncomment it, you should delete
% egpaper.aux before re-running latex.  (Or just hit 'q' on the first latex
% run, let it finish, and you should be clear).
\usepackage[pagebackref=true,breaklinks=true,letterpaper=true,colorlinks,bookmarks=false]{hyperref}

% \cvprfinalcopy % *** Uncomment this line for the final submission

\def\cvprPaperID{1611} % *** Enter the CVPR Paper ID here
\def\httilde{\mbox{\tt\raisebox{-.5ex}{\symbol{126}}}}

% Pages are numbered in submission mode, and unnumbered in camera-ready
\ifcvprfinal\pagestyle{empty}\fi
\begin{document}

%%%%%%%%% TITLE
\title{Visual Census Using Cars}

\author{First Author\\
Institution1\\
Institution1 address\\
{\tt\small firstauthor@i1.org}
% For a paper whose authors are all at the same institution,
% omit the following lines up until the closing ``}''.
% Additional authors and addresses can be added with ``\and'',
% just like the second author.
% To save space, use either the email address or home page, not both
\and
Second Author\\
Institution2\\
First line of institution2 address\\
{\tt\small secondauthor@i2.org}
}

\maketitle
%\thispagestyle{empty}

%%%%%%%%% ABSTRACT
\begin{abstract}
Detecting a large number of BMWs in images informs us that those images may be of a wealthy area. Conversely, knowing that our images were obtained from a wealthy neighborhood increases the likelihood of detecting expensive cars. We explore this relationship between demographic factors and fine-grained classes by performing large scale detection of over 2600 car classes and conducting a social analysis of unprecedented scale in computer vision. Using 45 million images from 200 of the biggest cities in the United States, we predict demographic factors such as neighborhood wealth, education levels and show that our results correlate well with census data. To facilitate our work, we have collected the largest and most challenging fine-grained dataset reported to date consisting of over 2600 classes of cars comprised of images from google Street View and other web sources,classified by car experts to account for even the most subtle of visual differences. 
\end{abstract}

\section{Introduction}
\begin{figure}[t]
\begin{center}
   \includegraphics[width=1\linewidth]{img/pull.png}
\end{center}
   \caption{Look at the car on the {\em left}. It is a Prius 2012. From the car only, can you guess where the owner lives and drives the car? What his or her highest degree is? And what is the household income of the owner? A car can tell us a thousand things, as it turns out. In this paper, we combine results from a fine-grained car detection algorithm with a number of social census data provided by the U.S. government, and are able to infer that Prius is the most popular car in the city of San Francisco, its owner often holds a college degree and has a household income of \$30,000 ({\em right})}
\label{fig:pull}
\end{figure}

%%%%%%%%% BODY TEXT
\begin{figure*}[t]
\begin{center}
   \includegraphics[width=1\linewidth]{img/dataset_figure.png}
\end{center}
   \caption{Examples of cars from our fine-grained dataset. Left: examples of cars from edmunds.com, cars.com and craigslist.com. Right: examples of cars from streetview images. Cars from streetview images tend to be lower resolution and are often occluded where as those from other sources are typically unoccluded and centered in the image.}
\label{fig:dataset1}
\end{figure*}
The artifacts which we choose to surround ourselves with tell us not only about ourselves but also about the society in which we live. In the 21st century, some of the most relevant objects defining people and their lifestyles are houses, clothes and cars. From a single figure such as fig.~\ref{fig:pull} of cars on the street, we can infer that the images in the first column are from wealthy neighborhoods where as those in the second column are from poor areas. We can also guess that the person next to the Tesla in Fig.~\ref{fig:pull} is wealthy and liberal. Traditionally, the most prevalent method for gathering such personal and demographic information is through surveys such as census and American community survey (ACS) projects. However, the emergence of large and diverse sets of data generated by people has enabled computer scientists and computational sociologists to gain interesting insights by analyzing massive user texts and social networks~\cite{jure}~\cite{nlp_people}. For example, recent work from~\cite{ngrams} analyzed \(\sim 1\)M books and presented results related to the evolution of the English language as well as various cultural phenomena.

On the computer vision side, a few pioneering works by Torralba et al, Berg et al, and Hedalgo et al have recently started to apply visual scene analysis techniques to infer characteristics of neighborhoods and cities~\cite{antonio}~\cite{mcdonalds}~\cite{mit_cvpr}~\cite{tamara}. In this work, we are also interested in using images to understand cities, neighborhoods and the demographic makeup of their inhabitants. However, instead of using global image statistics, we achieve this goal by detecting and classifying cars on the street. 95\% of American households own cars~\cite{car_stats}, and as seen in fig.~\ref{fig:pull} cars give a lot of information about individuals as well as neighborhoods. By using cars as a lens into understanding society, we are able to gain insights ranging from the demographic makeup of cities to neighborhood pollution levels.

Our contributions are two-fold. First, we offer a fine-grained car dataset of unprecedented scale. It has 2657 car classes consisting of nearly all car types produced in the world after 1990: with a total of 700,000 images from websites such as edmunds.com, cars.com, craigslist.com and Google Street View (Fig.~\ref{fig:dataset1}). We use our dataset to train a large scale fine-grained detection system, detecting cars in more than 45,000,000 Google Street View images collected from 200 of the largest American cities.

Second, we present a suite of interesting social analysis of American people and cities using our car detections. In Section~\ref{sec:social}, we show that from a single source of data, Google Street View images, we are able to predict diverse sets of important societal information typically gathered by different entities. We not only show good correlation with census data related to demographics, but can also predict information not present in census data such as neighborhood pollution levels. Finally, Section~\ref{sec:prior} presents preliminary results in exploring the use of demographic information to improve fine-grained car classification.
%------------------------------------------------------------------------
\section{Related Work}
\label{sec:related}
\textbf{City analysis via image features}. There has been recent interest in using images to characterize cities~\cite{mit_plos_1}~\cite{tamara}~\cite{paris}~\cite{antonio}~\cite{mit_cvpr}~\cite{mcdonalds}. ~\cite{mit_plos_1} created scores for perceptions of wealth, safety and uniqueness by asking people to rate images from 3 cities on a scale of 1\textendash10 and ~\cite{mit_cvpr}~\cite{tamara} predicted these scores using various global image features such as GIST~\cite{gist} and CNN~\cite{cnn}. In another line of work analyzing cities, ~\cite{antonio} perform city identity recognition after representing each city with higher level attributes. Doersch et al~\cite{paris} identify unique qualities of cities such as Paris and Prague and~\cite{mcdonalds} shows that given an image of a particular city location, it is possible to predict the most likely direction for the location of a McDonalds. While our work also shares the motive of city analysis through imagery, it differs in that we use fine-grained object recognition to achieve this goal. As shown in section~\ref{sec:social}, this allows us to perform much more extensive social and demographic analysis through imagery and also easily extend our analysis to many other cities without the need for additional labeling. \newline\newline
\textbf{Fine-grained object recognition}. Fine-grained object recognition is a difficult problem due to the high visual similarity between classes. Nevertheless, recent works such as ~\cite{ning}~\cite{cars} show impressive results by using part annotated datasets such as ~\cite{birds}~\cite{dogs}~\cite{cars} and augmenting state of the art object detection algorithms such as RCNN~\cite{rcnn}. However, it is difficult to evaluate fine-grained classification accuracy since there are no fine-grained datasets that match object classification datasets like imagenet~\cite{imagenet} in the number of classes or images. Recent works such as~\cite{birdsnap} have introduced larger scale fine-grained datasets and ~\cite{nyc3d} has introduced a 3D car dataset annotated with metadata such as location information. We introduce a geotagged car dataset with unprecedented scale in both the number of classes and images.\newline\newline
\textbf{Using GPS data to improve classification}. Although an increasing number of images that we interact with daily are associated with GPS tags, there are very few computer vision algorithms that take advantage of location based metadata. However, recent works such as~\cite{amir} use location information to assist in detecting objects such as trash cans and street lamps,~\cite{birdsnap} learns a spatio-temporal prior to improve bird classification and~\cite{nyc3d} uses some location information such as elevation to assist in car classification. Following the work of~\cite{birdsnap}, we explore the use of demographic data to improve fine-grained classification.

%------------------------------------------------------------------------
%\begin{figure} [t]
%\begin{center}
%\includegraphics[width=0.8\linewidth]{img/car_hierarchy.jpg}
%\end{center}
%\caption {Car class hierarchy. Classes are usually more visually similar when we travel down the tree.}
%\label{fig:hierarchy}
%\end{figure}

\begin{figure*} [t]
\begin{center}
%\raisebox{0.5\height}{
  \includegraphics[width=1\linewidth]{img/car_hierarchy.png}
%}
%\includegraphics[width=0.32\linewidth]{img/web.jpg}
%\includegraphics[width=0.32\linewidth]{img/street.jpg}
\end{center}
\caption {Left: A hierarchy of car classes in our dataset. Classes become more difficult to distinguish lower in the hierarchy, with differences extremely subtle at the year and trim level. Center: The number of images per class obtained from edmunds.com, cars.com, and craigslist.com. Right: The number of images per class from Street View.}
\label{fig:img_dist}
\end{figure*}

\section{Cars and Cities Dataset}
\label{sec:data}
\begin{figure}[t]
\begin{center}
   %\includegraphics[width=0.45\linewidth]{img/loc_prior.png}
   \includegraphics[width=1\linewidth]{img/bbox_figure.png}
\end{center}
   \caption{(a) Heatmap of bounding box scale. Each point represents a single bounding box from Street View. The color of each point color indicates the area, with red higher area. The magnitude at each point indicates the size of a bounding box centered at that location in a Street View image. (b) Heatmap of Street View bounding box coverage in an image. The magnitude at each point indicates the number of bounding boxes that include that point.}
\label{fig:loc-heat}
\end{figure}

\begin{table}
\begin{center}
\begin{tabular}{|l|c|c|c|}
\hline
\textbf{Attribute} & \textbf{Training} & \textbf{Validation} & \textbf{Test} \\
\hline\hline
Street View Images & 199,666 & 39,933 &159,732\\
Street View BBoxes & 34,712 & 6,915 &27,865\\
Product Shot Images & 313,099 & - &-\\
Product Shot BBoxes & 313,099 & - &-\\
Total Images &512,765&39,933&159,732\\
\hline
\end{tabular}
\end{center}
\caption{Dataset statistics for our training, validation, and test splits. ``BBox'' is shorthand for Bounding Box. Product shot bounding boxes and images are from craigslist.com, cars.com and edmunds.com.}
\end{table}

We collected 45 million images from 8 million GPS points by sampling the roads of 200 of the biggest US cities every 25m. For each GPS coordinate we gathered Street View images at 0, 60, 120, 180, 240, 300 degree rotations. In order to train a fine-grained car classifier to detect and classify the cars in our images, we created the largest ever reported fine-grained dataset of cars consisting of all the cars listed on a prominent car information website: edmunds.com (all cars manufactured after 1990). To assemble our car dataset we obtained images of all cars in edmunds.com (\(\sim\)18k cars) and grouped the cars into visually indistinguishable classes using a series of amazon mechanical turk tasks. After creating a class list, we collected additional images of cars from cars.com as well as craigslist and used AMT to annotate them with bounding boxes. Finally, we hired car experts to label \(\sim 70\)k bounding boxes of cars from the street view images with fine-grained lables. We also labeled cars from craigslist.com and cars.com by parsing the car posting titles. 


Table~\ref{table:data} summarizes the statistics of our dataset, Fig.~\ref{fig:dataset1} shows example images and Fig.~\ref{fig:loc-heat} visualizes the location and scale of car bounding boxes in the Street View images. As seen in Fig.~\ref{fig:loc-heat} and Fig.~\ref{fig:dataset1}, Street View images typically contain multiple cars per image where as images from sources such as craigslist.com contain one car per image. Bounding boxes from Street View images can also be located in many parts of the image, have a large range of sizes and are typically blurry and occluded. These  aspects of our dataset differentiate our data from other fine-grained datasets such as~\cite{birds} containing one centered and focused object per image. Fig.~\ref{fig:img_dist}a, shows a hierarchy of classes in our dataset where classes become increasingly visually indistinguishable while traveling down the tree. It can be seen that the difference between the fine-grained classes in our dataset is extremely subtle making it difficult for non-expert humans to distinguish. Finally Figs.~\ref{fig:img_dist}a and b show the distribution of Street View images and product shots (images from craigslist.com, cars.com and edmunds.com) for different classes. The image/class distribution for images from the 3 websites is very different from that of the Street View images. By collecting images from different sources we minimize the amount of bias present in our dataset.

\section{Detecting and classifying cars}
\label{sec:detection}
Although RCNN based fine-grained detection algorithms have reported state of the art results, ~\cite{rcnn}~\cite{ning}, its computational and memory requirements make it impractical for use in a large scale detection setting such as ours. In addition to memory requirements, detecting cars in our images would take \(\sim\)20s per image using a machine with a single GPU. Thus our pipeline, instead, consists of using DPM~\cite{dpm} to detect cars and a CNN ~\cite{alexnet} to classify them. We present details in the sections below.

\subsection{Car Detection}
Inorder to evaluate accuracy/speed trade off, we trained DPMS with different numbers of components and parts and used the model with the best tradeoff for detection. Our final algorithm employs a single component 8 part DPM and achieves an AP of 64.2\% while taking 5 secs per image. As a point of comparison, the highest AP (68.7\%) was achieved with a 5 component 8 part DPM which takes \(\sim\)22 secs per image. Detailed plots and timing measurements of other DPMs we have trained are discussed in our supplementary material.


\begin{table}
\begin{center}
\begin{tabular}{|l|c|}
\hline
\textbf{Attribute} & \textbf{Accuracy} \\
\hline\hline
Make & 66.38\%\\
Model & 51.83\% \\
Submodel & 77.74\% \\
%Year (5 bins) & X \\
Price & 61.61\% \\
Domestic/Foreign & 87.71\%\\
Country & 84.21\%\\
\hline
\end{tabular}
\end{center}
\caption{Classification accuracy on the test set for various car attributes.}
\label{table:att-acc}
\end{table}

\begin{figure}[t]
\begin{center}
   %\includegraphics[width=1\linewidth]{img/price_confusion.png}
   \includegraphics[width=1\linewidth]{img/submodel_confusion.png}
\end{center}
   \caption{Confusion matrix for car body types. Most misclassifications are between similar types of submodels such as sedans and coupes or extended cabs and a crew cabs (different types of trucks).} 
\label{fig:confusion}
\end{figure}

\begin{figure} [t]
\begin{center}
\includegraphics[width=1\linewidth]{img/good_det.png}
%\raisebox{-0.02\height}
% {
%\includegraphics[width=0.34\linewidth]{img/cars.jpg}
% }
\end{center}
\caption {An example of our car detections and classifications. The two cars in the image are correctly detected and classified as the classes shown on the right.}
\label{fig:dets}
\end{figure}

\subsection{Car Classification}
We use a standard CNN from ~\cite{alexnet} with ~\cite{caffe} to classify the DPM detections into one of 2657 fine-grained classes. Although our test set consists of street view images, as mentioned in sec.~\ref{sec:data} 61\% of our positive training images are composed of cars from other sources such as craigslist. Thus we add deformations such as blurring to these images during training to liken them to street view images. We give details of training the CNN in our supplementary material. At test time we take the top 10\% scoring DPM bounding boxes and classify them. This results in a 10x increase in speed but only a \(\sim\)2\% drop in AP as compared to using all the bounding boxes detected by DPM. We achieve an accuracy of 33.15\% on the true positive DPM bounding boxes and 31.27\% on the ground truth bounding boxes. Fig.~\ref{fig:dets} shows an example of our Street View detections. The cars are detected and classified correctly even though blurriness and occlusions in street view images makes this a difficult task. Fig.~\ref{fig:confusion} shows a confusion matrix for submodel level classifications. It can be seen that most of the errors are between highly similar submodels such as sedan and coupe.   

\subsection{Analyzing Hierarchical Classification Accuracy}
Some types of classification mistakes are more costly than others for the task of social analysis. For example, an error misclassifying 2001 Honda Accord lx to 2001 Honda Accord dx is not significant. However, misclassifying a 2012 BMW 3-series to a 1996 Honda Accord,for example, would create large errors in an analysis measuring the realtionship between the average car price or age in a zip code and median household income. In order to gain more insight into the types of errors our classifier makes, we measure the accuracy of classifying different car attributes. Table~\ref{table:att-acc} lists accuracies by various car attributes such as those in fig.~\ref{fig:img_dist}a and others like car price, year etc\ldots We can see that the accuracy is much higher after aggregating by different attributes.  

 \section{Societal analysis}
\label{sec:social}
In this section, we present societal analysis results from all 200 cities as well as case studies from those with available ground truth data. We divide our analysis into different sections below.

\subsection{What cars on the street tell us about people}
\subsubsection{Sanity Check: Cars on the street correlate well with registred cars}
How do cars on the street relate to the cars that people drive? Specifically, can we learn about the registered cars in a zip code from our street view detections?
We downloaded vehicle census data from Massachusetts, which is the only state to release extensive vehicle registration data, and found an extremely high Pearson correlation coefficient of 0.9 (p \(\sim\)0) between the number of cars we detected per zip code and the number of cars that are registered. The high correlation was only obtained after aggregating cars at the zip code level which shows that most people in MA drive within their zip code. 
After establishing a high correlation between the number of cars we detect and the number of registered cars, we also measured the correlation between the make of the detected and registered cars per zip code. As we can see in fig.~\ref{fig:ma_corrs} there is a high correlation for most of the makes. Thus the cars we detect from street view images contain useful information about the types of cars driven by people in a particular zip code.

\begin{table}
\begin{center}
\begin{tabular}{|l|c|r|}
\hline
\textbf{Census Variable} & \textbf{Car Attribute} & \textbf{Pearson r}  \\
\hline\hline
Household income & \# 1990-1994 cars & -0.42 \\
Household income & \# 1995-1999 cars & -0.40 \\
Household income & \# 2000-2004 cars & 0.21 \\
Household income & \# 2005-2009 cars & 0.46 \\
Household income & \% of foreign cars & 0.59 \\
Household income & \% of German cars & 0.57 \\
Household income & \% of US cars & -0.59 \\
Household income & Avg. price & 0.49 \\
Education: highschool & Avg. price & -0.21 \\
Education: college & Avg. price & 0.32 \\
Education: graduate scl. & Avg. price & 0.39 \\
\hline
\end{tabular}
\end{center}
\caption{Pearson correlation coefficient between various census variables and detected car attributes. All p values are \(\ll\) 0.01.}
\label{table:car-census-corrs}
\end{table}

\begin{figure}[t]
\begin{center}
   \includegraphics[width=0.9\linewidth]{img/averagePriceIncome.png}
\end{center}
   \caption {Scatter plot of average price of detected cars per zip code vs. median household income per zip code for all zip codes in our dataset.}
\label{fig:price-income-corr}
\end{figure}

\begin{figure*} [t]
\begin{center}
%\raisebox{-0.03\height}{
\includegraphics[width=1\linewidth]{img/boston_corr.png}
%}
%\raisebox{0.3\height}{
%  \includegraphics[width=0.3\linewidth]{img/boston_acura_corr.png}
%}
%\raisebox{0.3\height}{
%\includegraphics[width=0.3\linewidth]{img/boston_bmw_corr.png}
%}
\end{center}
\caption {Left: Pearson correlation coefficient between the number of detected and registered cars in Boston for each car make. Center: Scatter plot of detected BMWs per zip code vs. registered BMWs per zip code in Boston. Right: number of detected Honda's per zip code vs. registered Honda's per zip code in Boston.}
\label{fig:ma_corrs}
\end{figure*}

\subsubsection{What do rich/poor people drive?}
We gathered zip code level as well as census tract level 2007-2012 American Community Survey data for the 200 cities in our dataset and analyzed how the census data relates to statistics from our detected cars. 

Table \ref{table:car-census-corrs} shows correlation values between various attributes of the detected cars and median household income as well as education level per zip code. Fig.~\ref{fig:price-income-corr} shows a plot of median household income vs. average car price in a zip code. As expected, there is a high correlation between median household income and the average car price per zip code (r=0.49, p \(\sim\) 0). Our results also indicate that rich people prefer to drive foreign, especially German, cars (r=0.59). What is perhaps surprising is that there is a very high negative correlation (r=-0.55, p \(\sim\) 0) between the percentage of American cars in a zip code and median household income. So poor people live in places with many American cars.

Poor people also live near very old cars where as rich people live near newer ones. As table \ref{table:car-census-corrs} shows, the correlation between median household income and the number of cars in 1990-1994 is very negative and increases to a high positive 0.59 for cars in the 2005-2009 range. Finally, a perhaps not surprising result is that poor people live near cars with low miles per gallon (MPG). This corroborates~\cite{cal-traffic-study} study showing that poor people are more exposed to car pollution than rich people.
 
\begin{figure*}[t]
\begin{center}
    \includegraphics[width=1\linewidth]{img/income_price.png}
    %\includegraphics[width=0.45\linewidth]{img/price.png}
    %\includegraphics[width=0.45\linewidth]{img/income.png}
  %\raisebox{-.5\height}{
  % 
  %  \includegraphics[width=0.45\linewidth]{img/houston_income.png}
  %}
\end{center}
   \caption {Left: Heat map of average household income per zip code obtained from census data. Center: Heat map of average car price per zip code detected from our data. Right: Example of Street View images and car detections corresponding to zip codes with high and low incomes respectively. We detect many cheap cars in low income areas and expensive cars in high income areas.}
\label{fig:bos-sf-vis}
\end{figure*}

\subsubsection{How does education relate to cars on the street?}
As shown in \ref{table:car-census-corrs} there is a high negative correlation between the number of people with only a high school education and the average price of a car in a zip code. As expected, we also found a high correlation between the number of college educated people in a zip code and the average car price. What is perhaps surprising is that although there is a large increase in correlation coefficient from high school to college educated, the jump from college to graduate school is very low. Thus, there is a negligable difference in the price of cars driven by people who hold bachelors vs. graduate degrees.

\begin{figure}[t]
\begin{center}
  %\raisebox{-.02\height}
 %{
 %  \includegraphics[width=0.3\linewidth]{img/sf_density.png}
 %}
 %  \includegraphics[width=0.3\linewidth]{img/sf_mpg.png}
 %  \includegraphics[width=0.3\linewidth]{img/sf_air_cropped.png}
 %  \includegraphics[width=0.28\linewidth]{img/miami.png}
 %  \includegraphics[width=0.3\linewidth]{img/new_orleans.png}
 %  \includegraphics[width=0.26\linewidth]{img/portland.png}
    \includegraphics[width=1\linewidth]{img/mpg.png}
\end{center}
   \caption { Top right: Density of cars in San Francisco inversely weighted by their expected miles per gallon (MPG). Center: The inverse of weighted average of car MPG in San Francisco where the weights are the expected number of cars in a GPS point. Left: Ground Truth for Air quality (measured in annual particulate matter) in San Francisco from~\cite{ground_air}. Bottom: inverse weighted average of car MPG for 3 additional cities.}
\label{fig:pollution}
\end{figure}

\subsection{What cars on the street tell us about neighborhoods}
\subsubsection{Which neighborhoods are wealthy/poor?}
Intuitively, seeing many expensive cars on the street indicate that we are in a rich neighborhood and vice versa. Figure \ref{fig:bos-sf-vis} A shows a heat map of the average price of detected cars within a zip code and median household income in a zip code for Boston and figure \ref{fig:bos-sf-vis} B shows the same visualization for Houston. We can see that in both cities, the average car price in a zip code is a very good predictor of wealthy/un-wealthy neighborhoods.


\subsubsection{Which neighborhoods have high car pollution?}
Can our street view detections tell us anything about which neighborhoods are affected by highly polluting cars? We plotted a heat map of the expected number of cars per sample inversely weighted by the expected MPG of that sample. We also map the inverse of the weighted average of car MPG where the weights are the expected number of cars. The first measure should give us a rough idea of the location of highly polluting neighborhoods: for the same density of cars, areas with high MPG result in lower numbers than those with low MPG. For different densities of cars, the relative magnitude of the measure depends on both the density of cars and how efficient they are. The second measure, on the other hand, visualizes areas with a high concentration of low MPG cars.

Fig.~\ref{fig:pollution}A shows the weighted density of cars in San Francisco and B shows the inverse weighted MPG. Although we could not find ground truth data of car pollution, Fig.~\ref{fig:pollution}C is a map of San Francisco air quality measuring annual average particulate matter concentration (MPG) from all sources~\cite{ground_air}. To our surprise, their map seems to agree with Fig.~\ref{fig:pollution}B in most cases.

\subsection{What cars on the street tell us about cities}
\subsubsection{Which cities are more segregated?}
Which cities show high clustering of similarly priced cars? Specifically, which cities have expensive cars clustered together with other expensive cars and cheap cars clustered with other cheap cars? Given the high correlation between median household income and average car price, the answer to this question should give us a good indication of the cities that are most and least segregated. Following the analysis of ~\cite{mit_plos_1} we use the Moran I statistic to measure spatial autocorrelation where a value of 1 indicates perfect clustering of similar values, -1 indicates perfect dispersion and 0 indicates a random spatial arrangement (neither clustering nor dispersion). Fig.~\ref{fig:moran-i} plots the highest and lowest scoring cities as well as well as a few others in between. We can see that Reno shows the highest clustering where as Dover shows the lowest.

\begin{figure}[t]
\begin{center}
    \includegraphics[width=1\linewidth]{img/moran.png}
\end{center}
   \caption {Moran I scores for car prices in different cities. The highest and lowest scoring cities are shown as well as 5 cities with scores in between. Reno, NV exhibits the most amount of clustering by car price while Dover, CO exhibits very little clustering. The two maps for San Francisco and Boston show areas of high clustering where green indicates statistically significant clustering of expensive cars and red indicates statistically significant clustering of cheap cars.} 
\label{fig:moran-i}
\end{figure}

\subsubsection{Which cities are more patriotic?}
Which cities have the most number of domestic cars? As Fig.~\ref{fig:city_price}A shows the coastal cities have a high concentration of foreign made cars where as the midwest has a low concentration. This result agrees with ~\cite{foreign_domestic} who measured the ratio of American/foreign cars driven in the US. The city with the highest percentage of foreign cars was found to be San Francisco with 61\% of foreign cars where as Casper Wyoming had the least percentage (21\%).

\subsubsection{Which cities are wealthier?}
Which city has the most expensive cars on average? Fig.~\ref{fig:city_price}B maps the average car price for each city. The map shows that many of the east coast cities have expensive cars as well as some cities in the south such as Atlanta. We found the city with the most expensive cars to be New York with an expected price of \(\sim\)\$12k and the one with the least expensive cars to be El Paso (\(\sim\)\$7k). 

\begin{figure}[t]
\begin{center}
    \includegraphics[width=1\linewidth]{img/city_foreign_new.png}
    \includegraphics[width=1\linewidth]{img/foreign.png}
\end{center}
   \caption {Map of the percentage of foreign cars in each American city. San Francisco, CA has the highest percentage with 61\% and Casper, WY the lowest with 21\%. The most popular cars in cities with the highest and lowest percentages as well as 2 others inbetween are listed.} 
\label{fig:city_price}
\end{figure}

\begin{figure}[t]
\begin{center}
    \includegraphics[width=1\linewidth]{img/city_price_new.png}
\end{center}
   \caption {Map of the expected car price in each American city. New York, NY has the highest expected car price (\$11,829) while El Paso,TX has the lowest (\$7,079).}
\label{fig:city_price}
\end{figure}

\begin{table}
\begin{center}
\begin{tabular}{|l|c|r|}
\hline
\textbf{Attribute} & \textbf{Census Variable}& \textbf{Acc. Gain}\\
\hline\hline
Price & Median hh income & 0.33\%\\
Year  & Median hh income & 0.33\%\\
Make & \#  ppl in management & 0.30\%\\
Submodel & Median hh income & 0.30\%\\
Domestic & \# ppl in management & 0.27\%\\
Country & \# ppl in management & 0.27\%\\
\hline
\end{tabular}
\end{center}
\caption{Census variables resulting in the highest accuracy gain for each car attribute. ``hh'' is shorthand for house hold and ``ppl'' is shorthand for people. Using median household income as a prior for the car price or year results in the highest gain in accuracy.}
\label{table:prior-acc}
\end{table}

\section{Using social priors to improve classification}
\label{sec:prior}
This section explores the use of demographic census information as a prior to improve fine-grained detection and presents preliminary results run on our validation set. Intuitively, if a particular image was taken in a wealthy neighborhood, for example, one would expect the cars in that neighborhood to be expensive and viseversa. In order to use zip code level census variables as priors, we first calculated \(P(C|I,S)\) where \(C\) is the fine-grained class, \(I\) is an image and \(S\) \(\in\) \(\{\)\(S_{1}\)\ldots \(S_{n}\)\(\}\)is a particular zip code level census variable such as median household income. After applying Bayes' rule, assuming that the image and census data are conditionally independent given the class label, and applying Bayes' rule again we get:

\begin{equation}
P(C|I,S)\propto \frac{P(C|I)}{P(C)}P(C|S)
\label{eq:prior-eq}
\end{equation}

Where \(P(C|I)\) is the output of our CNN classifier. A naive way of using census variables such as the one above reduces accuracy by \(\sim\)5\% to ~26.1\%. This is not surprising given that we have over 2600 fine-grained classes, and many of them have similar attributes such as price. Thus, instead of using census variables directly as fine-grained class priors, we use them as priors for the car attributes. In order to incorporate these variables into our classification pipeline we can reformulate \(P(C|S)\) in equation~\ref{eq:prior-eq} as \(P(C|A)\)\(P(A|S)\) where \(A\) \(\in\) \(\{\)\(A_{1}\)\ldots\(A_{n}\)\(\}\) represents a car attribute such as price. After this modification, equation~\ref{eq:prior-eq} can be written as  

\begin{equation}
  P(C|I,S) \propto \frac{P(C|I)}{P(C)}P(C|A)P(A|S)
\end{equation}
We calculate \(P(C|I,S)\) for all car attributes and 30 different census variables, quantizing some car attributes and census variables such as car price and median household income into bins ranging from 2-20. Table~\ref{table:prior-acc} shows the highest accuracy numbers for various combinations of census variables and car attributes. It can be seen that using median household income and either car price or year give the highest accuracy gain. This result is to be expected since, as seen in section~\ref{sec:social}, there is a high correlation between median household income and car price and year. Although the accuracy gain at the fine-grained level is very slight (which is to be expected due to the large number of similar classes in our dataset). Our supplemental material discusses more extensive experiments and results in using census variables to improve our fine-grained classifications.

\section{Conclusion}
In conclusion, by analyzing car detections from 45 million images across 200 cities, we have shown that cars detected from street view images contain predictive information about our neighborhoods, cities and their demographic makeup. To facilitate this work, we have collected the largest and most challenging fine-grained dataset reported to date. For our future work we plan to perform more extensive social analysis\textemdash such as crime prediction and predicting changes in cities across time\textemdash using fine-grained detection. We also hope to further explore the use of demographic data to assist in fine-grained detection. 
{\small
\bibliographystyle{ieee}
\bibliography{egbib}
}

\end{document}

{\small
\bibliographystyle{ieee}
\bibliography{egbib}
}
\end{document}

 
